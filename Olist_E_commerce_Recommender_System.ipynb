{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- **NumPy** is the main library Python uses for heavy-duty math.\n",
        "\n",
        "- Google Colab just updated its servers to use the brand-new **NumPy 2.0**.\n",
        "\n",
        "- Our recommender library, **surprise**, was built and compiled using the older **NumPy 1.x**.\n",
        "\n",
        "- If **surprise** library is trying to talk to NumPy 2.0 using the \"language\" of NumPy 1.x, Then the new version of NumPy i.e. **NumPy 2.0** won't understand it, so it will crash.\n",
        "\n",
        "- **Solution** : We just need to tell Colab to install the older, stable version of NumPy that 'surprise' knows how to talk to."
      ],
      "metadata": {
        "id": "TeXnVYJeklmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 0: Fix NumPy Incompatibility\n",
        "# We are forcing Colab to use an older version of NumPy that works with 'surprise'\n",
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "25yV7qm4oOJR",
        "outputId": "d6ce49fa-e874-4b28-c706-211d9187f404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "26a56e22e63a4d30a58f5f07a0767626"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0: Setup & Installations:**\n",
        "\n",
        "First, we need to set up our environment. We'll be using pandas to manage our data and a special library called **surprise** which, as the name suggests, makes building recommender systems surprisingly easy!"
      ],
      "metadata": {
        "id": "Ll4q-ArOidRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewIFkCl7iQ3c",
        "outputId": "47de1799-11aa-4a77-faf1-55949c6f9855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.16.3)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2544603 sha256=d517682c931ef32fc095ba28999e798105a40f15260842e294412c69654a6893\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install the 'surprise' library\n",
        "# This is the main library we'll use for our first model.\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import all our tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- For Model 1: Collaborative Filtering ---\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# --- For Model 2: Content-Based Filtering ---\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl8YprojiuW2",
        "outputId": "48baa003-54ad-42fa-ac15-58f528df3cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Load Our Data\n",
        "\n",
        "Our data is split into many files. We need to load them and merge them together to get the information we need. We don't need all 9 files right away, just the key ones."
      ],
      "metadata": {
        "id": "OZ_AXvPnogSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load all the necessary CSV files\n",
        "# Make sure you've uploaded these files to your Colab environment!\n",
        "\n",
        "customers = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/olist_customers_dataset.csv')\n",
        "orders = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/olist_orders_dataset.csv')\n",
        "order_items = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/olist_order_items_dataset.csv')\n",
        "order_reviews = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/olist_order_reviews_dataset.csv')\n",
        "products = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/olist_products_dataset.csv')\n",
        "translations = pd.read_csv('/content/drive/MyDrive/Olist E-commerce Recommender System/product_category_name_translation.csv')\n",
        "\n",
        "print(\"All 6 key CSV files loaded successfully.\")\n",
        "print(\"Files ready for merging.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3FBGvwsjD3B",
        "outputId": "d0be952b-75af-4ae7-8017-2c076e321988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 6 key CSV files loaded successfully.\n",
            "Files ready for merging.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1: Collaborative Filtering (SVD):\n",
        "\n",
        "> SVD stands for **Singular Value Decomposition** — it’s a mathematical way to **break down a large matrix into smaller, simpler parts** so we can understand or work with it more easily.\n",
        "\n",
        "\n",
        "**The Idea**: We're going to find users who have similar \"tastes.\" To do this, we need to create one big table that links a **user** to a **product** and the **rating** they gave it.\n",
        "\n",
        "**Step 2:** Prepare Data for Model 1\n",
        "We need to join our tables to get these three columns:\n",
        "\n",
        "- **User**: customer_unique_id (from customers)\n",
        "\n",
        "- **Item**: product_id (from order_items)\n",
        "\n",
        "- **Rating**: review_score (from order_reviews)\n",
        "\n",
        "\n",
        "1. **SVD** - \tA method to break data into simpler parts\n",
        "\n",
        "2. **Used for** - \tDimensionality reduction, pattern discovery, noise removal, recommendations\n",
        "\n",
        "3. **Intuition** - Find hidden relationships in data\n",
        "\n",
        "4. **Example** -\tNetflix movie recommendations, LSA for text, PCA internally uses SVD"
      ],
      "metadata": {
        "id": "QUcJczPes6A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Merge the datasets\n",
        "print(\"Merging dataframes to get user-item-rating format...\")\n",
        "\n",
        "# 1. Link orders to customers to get the unique user ID\n",
        "merged_orders = orders.merge(customers, on='customer_id')\n",
        "\n",
        "# 2. Link order_items to reviews to get product IDs and scores\n",
        "merged_order_items = order_items.merge(order_reviews, on='order_id')\n",
        "\n",
        "# 3. Now, merge the two big dataframes to link users to their product reviews\n",
        "df_model_1 = merged_orders.merge(merged_order_items, on='order_id')\n",
        "\n",
        "# 4. We only need the 3 key columns for this model\n",
        "ratings_df = df_model_1[['customer_unique_id', 'product_id', 'review_score']]\n",
        "\n",
        "# 5. Clean up: drop any rows with missing values\n",
        "ratings_df = ratings_df.dropna()\n",
        "\n",
        "print(\"Data merging complete! Here's a sample of our ratings data:\")\n",
        "print(ratings_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ32iRt1r4U0",
        "outputId": "bc620fea-f8a2-4122-a218-dcad5ad6b964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging dataframes to get user-item-rating format...\n",
            "Data merging complete! Here's a sample of our ratings data:\n",
            "                 customer_unique_id                        product_id  \\\n",
            "0  7c396fd4830fd04220f754e42b4e5bff  87285b34884572647811a353c7ac498a   \n",
            "1  af07308b275d755c9edb36a90c618231  595fac2a385ac33a80bd5114aec74eb8   \n",
            "2  3a653a41f6f9fc3d2a113cf8398680e8  aa4383b373c6aca5d8797843e5594415   \n",
            "3  7c142cf63193a1473d2e66489a9ae977  d0b61bfb1de832b15ba9d266ca96e5b0   \n",
            "4  72632f0f9dd73dfee390c9b22eb56dd6  65266b2da20d04dbe00c5c2d3bb7859e   \n",
            "\n",
            "   review_score  \n",
            "0             4  \n",
            "1             4  \n",
            "2             5  \n",
            "3             5  \n",
            "4             5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train the SVD Model\n",
        "Now we use the surprise library. We'll use an algorithm called SVD (Singular Value Decomposition).\n",
        "\n",
        "Simple Explanation: Imagine a giant, mostly empty spreadsheet where every row is a user and every column is a product. SVD is a powerful math technique that \"compresses\" this sheet into two smaller ones. One sheet describes users by their \"hidden preferences\" (e.g., \"likes modern tech,\" \"is budget-conscious\") and the other describes products by their \"hidden attributes\" (e.g., \"is high-end,\" \"is practical\"). This is called Matrix Factorization."
      ],
      "metadata": {
        "id": "S5mTEfN62jUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Load the data into the 'surprise' library format\n",
        "# The Reader object tells 'surprise' what our rating scale is (1 to 5 stars)\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings_df, reader)\n",
        "\n",
        "print(\"Data loaded into Surprise format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBVGa4VX0g7w",
        "outputId": "04e7d870-0dc2-49da-a3de-91bb19d01718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into Surprise format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Train the SVD model\n",
        "# We'll split our data: 80% to train the model, 20% to test how good it is.\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# 'n_factors=100' means we are asking it to find 100 \"hidden preference\" types\n",
        "model_svd = SVD(n_factors=100, n_epochs=20, random_state=42)\n",
        "\n",
        "print(\"Training the SVD model... (This might take a minute or two)\")\n",
        "model_svd.fit(trainset)\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI3se0ke2nA2",
        "outputId": "036f8119-ef2a-4b68-f0c1-d0fb99cdb749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the SVD model... (This might take a minute or two)\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Test Model 1\n",
        "How do we know if it's any good? We use the test data we set aside. We'll calculate the RMSE (Root Mean Squared Error).\n",
        "\n",
        "Simple Explanation: RMSE tells us, on average, how \"off\" our model's predicted star rating was from the actual star rating. A lower number is better! An RMSE of 1.0 means we are, on average, about 1 star off in our predictions."
      ],
      "metadata": {
        "id": "sw9q881L5QXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Evaluate the SVD Model\n",
        "print(\"Evaluating model...\")\n",
        "predictions = model_svd.test(testset)\n",
        "\n",
        "# Calculate and print the RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"Test Set RMSE: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EewqH7eZ2pjV",
        "outputId": "e09151a5-0592-4683-f17a-73ad4973a52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "RMSE: 1.2681\n",
            "Test Set RMSE: 1.2680982230386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Content-Based Filtering (NLP)\n",
        "The Idea: What if a product is brand new and has no ratings? Model 1 fails. This model solves that! It reads the content of a product (in our case, its category) and finds other products with similar content.\n",
        "\n",
        "Step 5: Prepare Data for Model 2\n",
        "We'll use the products file and the translations file to get the English category names for each product.\n"
      ],
      "metadata": {
        "id": "5IDcccdq5Yqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Load and prepare data for content-based model\n",
        "print(\"Loading product and translation data...\")\n",
        "\n",
        "# We only need the product_id and its category\n",
        "products_df = products[['product_id', 'product_category_name']]\n",
        "\n",
        "# Merge with translations to get English names\n",
        "products_with_names = products_df.merge(translations, on='product_category_name', how='left')\n",
        "\n",
        "# Clean up: Fill missing categories with an empty string\n",
        "products_with_names['product_category_name_english'] = products_with_names['product_category_name_english'].fillna('')\n",
        "\n",
        "# We'll also merge in the product name from the 'order_items' df (a bit of a hack, but it gives us a name)\n",
        "# This is just to make our final output look nicer\n",
        "product_names = order_items[['product_id']].drop_duplicates()\n",
        "# This part is tricky in Olist, as product names aren't in the product table. We'll skip it for simplicity\n",
        "# and just use the product_id and category.\n",
        "\n",
        "print(\"Product data for Model 2 is ready:\")\n",
        "print(products_with_names.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETzB1qIp5Sw7",
        "outputId": "96a18b95-b39f-4317-c080-76059d1e16f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading product and translation data...\n",
            "Product data for Model 2 is ready:\n",
            "                         product_id  product_category_name  \\\n",
            "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
            "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
            "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
            "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
            "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
            "\n",
            "  product_category_name_english  \n",
            "0                     perfumery  \n",
            "1                           art  \n",
            "2                sports_leisure  \n",
            "3                          baby  \n",
            "4                    housewares  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Vectorize the Content (TF-IDF)\n",
        "How does a computer read \"home_decor\" or \"sports_leisure\"? It can't. We have to turn the words into numbers. We'll use TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "Simple Explanation: TF-IDF is a clever way to score how \"important\" a word is to a document. It gives a high score to words that appear a lot in one product's category but are rare in all other categories. This helps find unique, defining words."
      ],
      "metadata": {
        "id": "kXBQKZJd5vQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Create the TF-IDF Matrix\n",
        "# 1. Initialize the TF-IDF Vectorizer\n",
        "# 'stop_words='english'' tells it to ignore common words like 'and', 'the', 'is'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# 2. Fit and transform the category names into a matrix of numbers\n",
        "print(\"Fitting TF-IDF Vectorizer...\")\n",
        "tfidf_matrix = tfidf.fit_transform(products_with_names['product_category_name_english'])\n",
        "\n",
        "print(\"TF-IDF Matrix created:\")\n",
        "print(tfidf_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzBCFvsf5rNC",
        "outputId": "7710317e-e279-41bd-ce51-77761c1ced96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TF-IDF Vectorizer...\n",
            "TF-IDF Matrix created:\n",
            "(32951, 71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Calculate Similarity (Cosine Similarity)\n",
        "Now that all our products are represented as number vectors, we can compare them. We'll use Cosine Similarity.\n",
        "\n",
        "Simple Explanation: This measures the \"angle\" between two product vectors. If two products are very similar (e.g., both \"baby_toys\"), the angle between them is tiny (score near 1). If they are very different (e.g., \"baby_toys\" and \"car_parts\"), the angle is large (score near 0)."
      ],
      "metadata": {
        "id": "df4PYyNX51os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Compute the Cosine Similarity Matrix\n",
        "print(\"Calculating Cosine Similarity matrix...\")\n",
        "# This creates a giant matrix where cell (i, j) is the similarity score between product i and product j\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "print(f\"Cosine similarity matrix shape: {cosine_sim.shape}\")\n",
        "print(\"Model 2 built successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRgQ1jOv5x48",
        "outputId": "a4f22e14-9ed7-41be-f332-c267cbfef32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Cosine Similarity matrix...\n",
            "Cosine similarity matrix shape: (32951, 32951)\n",
            "Model 2 built successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Get Recommendations!\n",
        "Now for the fun part. Let's create two functions to use our models."
      ],
      "metadata": {
        "id": "QNxel5Gc58nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Create a function to get Content-Based recommendations\n",
        "# We need a way to map a product_id to its index number in the matrix\n",
        "indices = pd.Series(products_with_names.index, index=products_with_names['product_id']).drop_duplicates()\n",
        "\n",
        "def get_similar_products(product_id, n=10):\n",
        "    try:\n",
        "        # 1. Get the index of the product we want to match\n",
        "        idx = indices[product_id]\n",
        "    except KeyError:\n",
        "        return f\"Product ID {product_id} not found.\"\n",
        "\n",
        "    # 2. Get the similarity scores for this product with all other products\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # 3. Sort the products based on their similarity score\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # 4. Get the scores of the top 10 most similar products (skip index 0, that's the product itself)\n",
        "    sim_scores = sim_scores[1:n+1]\n",
        "\n",
        "    # 5. Get the original indices of those top products\n",
        "    product_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # 6. Return the product_ids and categories of the most similar items\n",
        "    return products_with_names[['product_id', 'product_category_name_english']].iloc[product_indices]"
      ],
      "metadata": {
        "id": "y0evtSqy54FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: TEST MODEL 2!\n",
        "# Let's pick a random product ID from our order_items\n",
        "sample_product_id = order_items['product_id'].sample(1).values[0]\n",
        "original_category = products_with_names.loc[products_with_names['product_id'] == sample_product_id, 'product_category_name_english'].values[0]\n",
        "\n",
        "print(f\"--- Recommendations for Product: {sample_product_id} ---\")\n",
        "print(f\"--- Original Category: {original_category} ---\\n\")\n",
        "print(\"--- Top 10 Similar Products: ---\")\n",
        "\n",
        "recommendations = get_similar_products(sample_product_id, n=10)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLBjcK_O6A4Y",
        "outputId": "6a50deb2-9739-4aeb-b794-517d4835acc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Recommendations for Product: b166907a5770631b7deedd0891b1b7ab ---\n",
            "--- Original Category: housewares ---\n",
            "\n",
            "--- Top 10 Similar Products: ---\n",
            "                           product_id product_category_name_english\n",
            "25   8ba4f2a4ae695d26e5626c1bf710975e                    housewares\n",
            "38   e6af694343b45b56304ad91974a110b9                    housewares\n",
            "109  67bea89008edcb996cfe4e3d062b62a8                    housewares\n",
            "114  2be2be0a6a5916840503fdf50808ebcb                    housewares\n",
            "135  bb09cce52b336261572a5a7e25a33795                    housewares\n",
            "158  722fb67c17907e21734449c091420bf5                    housewares\n",
            "167  f9471562478eba8761bc985b968a0092                    housewares\n",
            "170  c7147724cd430269c6296fc758c0a086                    housewares\n",
            "184  a85543a371d5cfafedb80a8177a692b5                    housewares\n",
            "188  9aa70106d14b83c7ad033592870b2b30                    housewares\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Conclusion\n",
        "And there you have it! You've successfully:\n",
        "\n",
        "Loaded and merged a complex, multi-file dataset.\n",
        "\n",
        "Built a Collaborative Filtering model (SVD) to predict user ratings.\n",
        "\n",
        "Built a Content-Based Filtering model (TF-IDF) to find similar products."
      ],
      "metadata": {
        "id": "JROA3t-N6MZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We need to create a func for model 1:"
      ],
      "metadata": {
        "id": "wiaKWQSS8s6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: DEFINE THE SVD RECOMMENDATION FUNCTION\n",
        "\n",
        "def get_top_n_recommendations_svd(user_id, n=10):\n",
        "    # 1. Get a list of all item IDs\n",
        "    all_item_ids = ratings_df['product_id'].unique()\n",
        "\n",
        "    # 2. Get a list of items the user has already rated\n",
        "    items_rated_by_user = ratings_df.loc[ratings_df['customer_unique_id'] == user_id, 'product_id']\n",
        "\n",
        "    # 3. Get items the user has *not* rated (the candidates for recommendation)\n",
        "    items_to_predict = np.setdiff1d(all_item_ids, items_rated_by_user)\n",
        "\n",
        "    # 4. Predict ratings for all unrated items\n",
        "    # We create a \"test set\" for this user and all items they haven't seen\n",
        "    test_set_for_user = [[user_id, item_id, 0] for item_id in items_to_predict]\n",
        "\n",
        "    # 5. Predict all the ratings\n",
        "    user_predictions = model_svd.test(test_set_for_user)\n",
        "\n",
        "    # 6. Sort predictions by estimated rating\n",
        "    user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    # 7. Return the top-N predicted items\n",
        "    top_n = user_predictions[:n]\n",
        "\n",
        "    top_n_item_ids = [pred.iid for pred in top_n]\n",
        "    return top_n_item_ids\n",
        "\n",
        "print(\"Function 'get_top_n_recommendations_svd' is now defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX7szE6tC7zA",
        "outputId": "d51a9482-f982-41f3-dfac-c10e9452c572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'get_top_n_recommendations_svd' is now defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVD Model Test 1: The \"Power User\"\n",
        "What it is: Let's find a user who has left many reviews. Our SVD model should have a good \"understanding\" of their taste, so the recommendations should be personalized."
      ],
      "metadata": {
        "id": "BHTesml7Dntn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: SVD Test Case (Power User)\n",
        "power_users = ratings_df['customer_unique_id'].value_counts()\n",
        "power_user_id = power_users.idxmax() # .idxmax() gets the ID of the top user\n",
        "num_reviews = power_users.max()\n",
        "\n",
        "print(f\"--- Testing SVD Model with a Power User ---\")\n",
        "print(f\"User ID: {power_user_id}\")\n",
        "print(f\"Number of reviews this user left: {num_reviews}\\n\")\n",
        "\n",
        "print(f\"--- Top 10 Recommendations for this Power User: ---\")\n",
        "recommendations = get_top_n_recommendations_svd(power_user_id, n=10)\n",
        "\n",
        "# We need to get the product names for these IDs\n",
        "recommended_products = products_with_names[products_with_names['product_id'].isin(recommendations)]\n",
        "print(recommended_products[['product_id', 'product_category_name_english']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J21Wi8mYDqSG",
        "outputId": "391de217-ae00-4a58-a1bd-e406c4cef263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing SVD Model with a Power User ---\n",
            "User ID: d97b3cfb22b0d6b25ac9ed4e9c2d481b\n",
            "Number of reviews this user left: 24\n",
            "\n",
            "--- Top 10 Recommendations for this Power User: ---\n",
            "                             product_id product_category_name_english\n",
            "2269   88dd63919fc9ab693803578a04a20209         computers_accessories\n",
            "8290   d1c427060a0f73f6b889a5c7c61f2ac4         computers_accessories\n",
            "9367   57e089e3103f5cda6a4ce23b77399bdb                          baby\n",
            "21450  698b3ddae2f0b80c2a48fb40624ca4e4               furniture_decor\n",
            "24842  3e4176d545618ed02f382a3057de32b4           luggage_accessories\n",
            "27244  a7d756e8f7c4b7e5b679e248a57d91ec      fashion_bags_accessories\n",
            "30397  3af6d5f9fdb78f106c003ce49d7f0186                 health_beauty\n",
            "31561  6109d0cae3bcb57d579bc0fab6e61814           luggage_accessories\n",
            "31807  73326828aa5efe1ba096223de496f596                          food\n",
            "31832  475e8a9ddbebf13af503d1c7eccadb1a              office_furniture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVD Model Test 2: The \"New User\" (Cold Start Problem)\n",
        "What it is: Let's find a user who only left one review. This is the \"cold start\" problem. The model has very little data, so it will probably just recommend popular, generic items."
      ],
      "metadata": {
        "id": "1WO9kEwbDtqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: SVD Test Case (New User)\n",
        "new_users = ratings_df['customer_unique_id'].value_counts()\n",
        "new_user_id = new_users[new_users == 1].index[0] # Get the first user with exactly 1 review\n",
        "\n",
        "print(f\"--- Testing SVD Model with a 'New' User ---\")\n",
        "print(f\"User ID: {new_user_id}\\n\")\n",
        "\n",
        "print(f\"--- Top 10 Recommendations for this 'New' User: ---\")\n",
        "recommendations = get_top_n_recommendations_svd(new_user_id, n=10)\n",
        "\n",
        "recommended_products = products_with_names[products_with_names['product_id'].isin(recommendations)]\n",
        "print(recommended_products[['product_id', 'product_category_name_english']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM9FM-ftD2_Z",
        "outputId": "57f1777b-cede-44f9-a1ec-923eb30b8174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing SVD Model with a 'New' User ---\n",
            "User ID: 7d2252746734931a8177e2680680eeeb\n",
            "\n",
            "--- Top 10 Recommendations for this 'New' User: ---\n",
            "                             product_id product_category_name_english\n",
            "8565   afeeea6271148ee1bb15173b8187c431                     telephony\n",
            "9073   a3ceb95649a48c0c54ae4bd1dd66d035                     telephony\n",
            "9367   57e089e3103f5cda6a4ce23b77399bdb                          baby\n",
            "12648  c7b3b8509e06ae21abdd78b541215cda                     perfumery\n",
            "13444  c1617123e66d2491ca93ceadfd36203e                bed_bath_table\n",
            "16147  79366d6a24de9351b7ca6e3cf75a68ec              small_appliances\n",
            "16571  4d38a4daf13a87012b73156f834afec0                bed_bath_table\n",
            "20966  e7f85e7f0203b7b95cc1b4c21b4b070c                    cool_stuff\n",
            "24842  3e4176d545618ed02f382a3057de32b4           luggage_accessories\n",
            "31807  73326828aa5efe1ba096223de496f596                          food\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content-Based Model Test 1: Specific Category\n",
        "What it is: Let's test Model 2. This model doesn't know about users. It only knows about product similarity. If we give it a product from health_beauty, it should give us other products from health_beauty."
      ],
      "metadata": {
        "id": "mbIg9t94D8PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Content-Based Test (Specific Category)\n",
        "specific_product = products_with_names[products_with_names['product_category_name_english'] == 'health_beauty'].sample(1)\n",
        "specific_product_id = specific_product['product_id'].values[0]\n",
        "original_category = specific_product['product_category_name_english'].values[0]\n",
        "\n",
        "print(f\"--- Testing Content-Based Model with a Specific Product ---\")\n",
        "print(f\"Product ID: {specific_product_id}\")\n",
        "print(f\"Original Category: {original_category}\\n\")\n",
        "\n",
        "print(f\"--- Top 10 Similar Products: ---\")\n",
        "# This uses the 'get_similar_products' function already in your notebook\n",
        "recommendations = get_similar_products(specific_product_id, n=10)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6XHMH8kD_7F",
        "outputId": "736cf953-3e8b-4092-ab21-bb1bbef6d303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Content-Based Model with a Specific Product ---\n",
            "Product ID: e4bf89766decbc6dd5e5c29edff02990\n",
            "Original Category: health_beauty\n",
            "\n",
            "--- Top 10 Similar Products: ---\n",
            "                           product_id product_category_name_english\n",
            "49   c5d8079278e912d7e3b6beb48ecb56e8                 health_beauty\n",
            "62   36555a2f528d7b2a255c504191445d39                 health_beauty\n",
            "75   e586ebb6022265ae1eea38f46ffe3ead                 health_beauty\n",
            "80   75b4372e69a42f8ae1d908c076f547b2                 health_beauty\n",
            "81   3569d4374a919941a50f57371b1dc93d                 health_beauty\n",
            "91   3a6a0247ced9dcb444b46caafdcdd368                 health_beauty\n",
            "92   adf591c625cb265c12bc6749d3a2f757                 health_beauty\n",
            "156  50556c630443502c11acde1c320fe278                 health_beauty\n",
            "157  88d2c501ec765f5d7e8038fa6aab0e62                 health_beauty\n",
            "193  b29ca3d3127057c43ef4b364bbe360ea                 health_beauty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content-Based Model Test 2: Niche Category\n",
        "What it is: Let's try another one to be sure. How about computers_accessories?"
      ],
      "metadata": {
        "id": "UokJKf0YEDTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Content-Based Test (Niche Category)\n",
        "niche_product = products_with_names[products_with_names['product_category_name_english'] == 'computers_accessories'].sample(1)\n",
        "niche_product_id = niche_product['product_id'].values[0]\n",
        "original_category = niche_product['product_category_name_english'].values[0]\n",
        "\n",
        "print(f\"--- Testing Content-Based Model with a Niche Product ---\")\n",
        "print(f\"Product ID: {niche_product_id}\")\n",
        "print(f\"Original Category: {original_category}\\n\")\n",
        "\n",
        "print(f\"--- Top 10 Similar Products: ---\")\n",
        "recommendations = get_similar_products(niche_product_id, n=10)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TInR0GCeEGo0",
        "outputId": "eb16eef5-f577-4bc1-f5d8-f2402a754938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Content-Based Model with a Niche Product ---\n",
            "Product ID: eecc2c78b528d8073b4f1c4bddf92aae\n",
            "Original Category: computers_accessories\n",
            "\n",
            "--- Top 10 Similar Products: ---\n",
            "                           product_id product_category_name_english\n",
            "27   c78b767da00efb70c1bcccab87c28cd5         computers_accessories\n",
            "28   a0253d43394dd4da9a5d7b1f546f1a32         computers_accessories\n",
            "89   c478b1bbf9ec8c5691f37ccb83187386         computers_accessories\n",
            "101  a2e2851eae0aebb8ee4df32348b42e2b         computers_accessories\n",
            "171  dbb399a8be7395d5b136d49fcdce13df         computers_accessories\n",
            "177  8e71b24c3e25a92fef6176120a67fac7         computers_accessories\n",
            "210  21db47f6493b06e8e7fc562ec9890e77         computers_accessories\n",
            "239  9e48435521202c8795e21ac42efcc761         computers_accessories\n",
            "264  a1bf559ac1eab015ba992bd76d9d76c7         computers_accessories\n",
            "284  d68bd4dedccc5545b1ff6629de8fb021         computers_accessories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in this project we created two different types of recommeders.\n",
        "\n",
        "Here’s the simple breakdown of the difference:\n",
        "\n",
        "\n",
        "1. ***get_top_n_recommendations_svd(user_id, n=10)***\n",
        "\n",
        "- **What it Asks:** \"Which products would this *user like the most?*\"\n",
        "\n",
        "- **How it Works (Collaborative Filtering):** This function uses the **model_svd** (our *Matrix Factorization model*). It looks at the past behavior of all users to find other users with similar tastes to the one you provided. It then recommends products that those similar users liked but this user hasn't seen yet.\n",
        "\n",
        "- **Input:** It needs a *user_id*.\n",
        "\n",
        "- **Key Idea:** It's all about personalization based on user behavior. It recommends what you might like, even if the product is in a totally different category from what you've bought before.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________\n",
        "\n",
        "2. ***get_similar_products(product_id, n=10)***\n",
        "\n",
        "- **What it Asks:** \"Which products are *most similar to this product?*\"\n",
        "\n",
        "- **How it Works (Content-Based Filtering):** This function uses the *cosine_sim matrix (our NLP model)*. It ignores all users and only looks at the *product's content (in our case, its category)*. It finds other products that have the *most similar category text.*\n",
        "\n",
        "- **Input:** It needs a *product_id*.\n",
        "\n",
        "- **Key Idea:** It's all about similarity. It's great for \"Customers who viewed this item also viewed...\" or for solving the \"cold start\" problem (recommending new products that have no ratings yet).\n",
        "\n",
        "\n",
        "__________________________________________________________________\n",
        "**Simple Analogy**:\n",
        "\n",
        "1. ***get_top_n_recommendations_svd (SVD):***  \n",
        "This is like asking a friend who has the same taste in movies as you what you should watch next. They might recommend a comedy, even if you just watched a sci-fi, because they know you.\n",
        "\n",
        "\n",
        "\n",
        "2. ***get_similar_products (Content):***   \n",
        " This is like clicking on the \"sci-fi\" genre tag on a streaming site. It will only show you other sci-fi movies, regardless of what you or other users like."
      ],
      "metadata": {
        "id": "VHpRTrdhu-kJ"
      }
    }
  ]
}